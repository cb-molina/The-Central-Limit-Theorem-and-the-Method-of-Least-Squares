# The-Central-Limit-Theorem-and-the-Method-of-Least-Squares
Taking measurements and comparing the results to theoretical expectations is a major part of science and engineering. Non-ideal conditions, limited measurement instrumentation, the nature of the physical phenomena being measured, and dealing with unknown physical phenomena during experimentation and measurement results in uncertainties and data that may be imperfect and not precise. Because of this, it may be necessary to make incomplete conclusions or models of the problem. Some of these models may contain parameters that are determined empirically. Statistical analysis like the Central Limit Theorem and the Method of Least Squares make it possible to derive such parameters and make progressive conclusions. The Central Limit Theorem states that if measured variables have a large enough number of independent degrees of freedom, the distribution of these variables goes asymptotically to a normal distribution. Distributions reflect the stochastic nature of the uncertainties associated with the measurements and the nature of the quantity itself. The Central Limit Theorem implies that the same probabilistic and statistical methods applicable to normal distributions can be applied to other types of distributions. The Least Squares Method approximates the solution of over-determined systems by minimizing the sum of the squares of the residuals made within the results of the equations. This can be utilized to approximate the parameters of the resulting measurement. In this report, we shall discuss the application of the linear least-squares fit to a straight line.
